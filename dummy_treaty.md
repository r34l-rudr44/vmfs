# International Treaty on Advanced AI System Verification and Governance
## Treaty on the Verification of Frontier AI Systems (TVFAIS)

**Preamble**

The Parties to this Treaty,

Recognizing the transformative potential of frontier artificial intelligence systems and their capacity to benefit humanity,

Acknowledging the significant risks posed by unregulated development and deployment of advanced AI systems,

Concerned about the potential for misuse, catastrophic accidents, and threats to global security,

Committed to establishing robust verification mechanisms that ensure transparency, accountability, and safety,

Desiring to create a framework for international cooperation in AI governance,

Have agreed as follows:

---

## Article 1: Definitions

For the purposes of this Treaty:

(a) "Frontier AI System" means any artificial intelligence system that:
   - Requires computational resources exceeding 10^26 floating-point operations (FLOPs) for training
   - Exhibits capabilities in reasoning, planning, or autonomous decision-making that exceed current state-of-the-art systems
   - Is designed or deployed for use in critical infrastructure, military applications, or systems with potential for significant societal impact

(b) "Compute Threshold" means the computational resources measured in FLOPs used during the training phase of an AI system

(c) "Deployment" means the release, distribution, or operational use of a Frontier AI System in any environment, whether public or private

(d) "Post-Training Modification" means any significant alteration to a Frontier AI System after its initial training, including fine-tuning, alignment adjustments, or capability enhancements

(e) "Model Lineage" means the complete record of a model's development history, including training data sources, architectural changes, and all modifications

---

## Article 2: Verification Requirements

### Section 2.1: Compute Monitoring

1. All Parties shall implement mandatory compute monitoring for any AI system development that exceeds 10^24 FLOPs.

2. Parties shall require developers to:
   - Install secure hardware-based monitoring systems in all AI training facilities
   - Report compute usage above 10^25 FLOPs to the International AI Verification Agency (IAVA) within 30 days
   - Maintain detailed logs of all compute resources used during training, including:
     * Total FLOPs consumed
     * Peak computational power
     * Duration of training runs
     * Number and type of accelerators used

3. Compute verification above 10^26 FLOPs shall trigger mandatory international inspection and compliance review.

### Section 2.2: Model Lineage Tracking

1. Parties shall require developers to maintain comprehensive model lineage records that include:
   - Complete training dataset documentation
   - All architectural modifications and version history
   - Sources of training data and data provenance
   - Details of all fine-tuning and post-training modifications
   - Chain of custody for model weights and parameters

2. Model lineage records must be verifiable through cryptographic attestation and must be retained for a minimum of 10 years.

3. Parties shall establish a global model registry where all Frontier AI Systems must be registered with their complete lineage information.

### Section 2.3: Deployment Controls

1. No Frontier AI System may be deployed without:
   - Prior safety assessment and risk evaluation
   - Independent third-party audit
   - Government approval from the Party of origin
   - Notification to all Parties at least 90 days before deployment

2. Deployment in critical infrastructure sectors (energy, finance, healthcare, transportation) requires:
   - Enhanced verification procedures
   - Continuous monitoring during operation
   - Regular compliance audits
   - Incident reporting mechanisms

3. Military deployment of Frontier AI Systems requires:
   - Explicit authorization from the deploying Party's highest security authority
   - Notification to the IAVA
   - Compliance with additional security protocols
   - Prohibition of fully autonomous weapons systems without human oversight

### Section 2.4: Post-Training Safety Modifications

1. Parties shall require developers to implement mechanisms that allow for post-training safety modifications, including:
   - Capability to apply safety patches and updates
   - Ability to modify model behavior in response to identified risks
   - Procedures for emergency intervention and model shutdown

2. Any post-training modification that:
   - Increases model capabilities by more than 10%
   - Alters core safety mechanisms
   - Changes the model's intended use case
   
   Shall require re-verification and compliance review equivalent to initial deployment requirements.

3. Parties shall establish technical standards for implementing post-training modifications that maintain model integrity and safety.

---

## Article 3: Verification Mechanisms

### Section 3.1: Mandatory Verification Tools

Parties agree to implement the following verification mechanisms:

1. **Hardware-Based Compute Monitoring**: Secure enclaves and trusted execution environments that cryptographically verify compute usage

2. **Model Watermarking**: Imperceptible identifiers embedded in model outputs to enable traceability

3. **Third-Party Audits**: Independent expert evaluation of model safety, capabilities, and compliance

4. **Declaration Regimes**: Mandatory self-reporting of training runs, model releases, and significant modifications

5. **Remote Sensing**: Satellite and other remote monitoring of large-scale compute facilities

### Section 3.2: Verification Agency

1. The International AI Verification Agency (IAVA) shall be established to:
   - Monitor compliance with this Treaty
   - Conduct inspections of AI development facilities
   - Maintain the global model registry
   - Investigate violations and coordinate enforcement

2. IAVA inspectors shall have the right to:
   - Access relevant facilities and data for verification purposes
   - Review compute logs and model lineage records
   - Interview developers and review documentation
   - Verify compliance with declared capabilities and restrictions

3. All inspections shall respect intellectual property rights while ensuring adequate verification.

---

## Article 4: Compliance and Enforcement

1. Parties shall establish national regulatory bodies responsible for:
   - Monitoring compliance within their jurisdiction
   - Enforcing verification requirements
   - Reporting violations to the IAVA
   - Coordinating with other Parties

2. Violations of this Treaty may result in:
   - Suspension of development or deployment activities
   - Financial penalties
   - Trade restrictions on AI-related technologies
   - Referral to international dispute resolution mechanisms

3. Parties agree to cooperate in enforcement actions, including:
   - Information sharing about violations
   - Coordinated sanctions
   - Technical assistance for compliance

---

## Article 5: Technical Feasibility and Implementation

1. Parties recognize that verification mechanisms must balance:
   - Technical feasibility with current technology
   - Effectiveness in detecting violations
   - Cost and accessibility for all Parties
   - Respect for national sovereignty

2. Priority shall be given to verification mechanisms that:
   - Are technically mature and proven
   - Can be implemented by both developed and developing nations
   - Minimize intrusion into proprietary information
   - Provide reliable and auditable results

3. Parties shall regularly review and update verification requirements based on:
   - Advances in technology
   - Effectiveness of current mechanisms
   - Emerging risks and capabilities
   - Feedback from implementation

---

## Article 6: Global South Considerations

1. Parties recognize that verification requirements must be accessible to developing nations.

2. Developed Parties shall provide:
   - Technical assistance for implementing verification mechanisms
   - Financial support for compliance infrastructure
   - Training and capacity building
   - Access to verification technologies at reasonable cost

3. Verification mechanisms shall be designed to:
   - Minimize barriers to entry for smaller developers
   - Support innovation in developing nations
   - Avoid creating technological monopolies
   - Ensure equitable participation in AI governance

---

## Article 7: Sovereignty and National Security

1. Nothing in this Treaty shall be interpreted as:
   - Requiring Parties to disclose classified information
   - Compromising national security interests
   - Interfering with legitimate defense capabilities
   - Violating intellectual property rights

2. Verification procedures shall respect:
   - National sovereignty
   - Constitutional protections
   - Privacy laws
   - Commercial confidentiality

3. Parties may invoke national security exceptions, subject to:
   - Notification to other Parties
   - Review by the IAVA
   - Proportionality requirements

---

## Article 8: Entry into Force and Amendments

1. This Treaty shall enter into force 180 days after the deposit of instruments of ratification by 20 Parties, including at least 5 Parties that are major AI developers.

2. Amendments to this Treaty may be proposed by any Party and shall enter into force after approval by two-thirds of the Parties.

3. Parties may withdraw from this Treaty with 12 months' written notice.

---

## Article 9: Dispute Resolution

1. Disputes arising from the interpretation or application of this Treaty shall be resolved through:
   - Direct negotiations between Parties
   - Mediation through the IAVA
   - Arbitration by an agreed tribunal
   - Referral to appropriate international courts

2. Parties agree to resolve disputes in good faith and in a timely manner.

---

**Done at Geneva, this [date]**

**In witness whereof, the undersigned, being duly authorized, have signed this Treaty.**

---

*This Treaty establishes comprehensive verification requirements for frontier AI systems, emphasizing compute monitoring, model lineage tracking, deployment controls, and post-training safety modifications. It balances technical feasibility with political tractability while considering the needs of both developed and developing nations.*
